{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ########################################\n",
    "import numpy as np ###############################\n",
    "import scipy.stats as stats ######################\n",
    "import math ######################################\n",
    "import matplotlib.pyplot as plt###################\n",
    "from sklearn.metrics import mean_squared_error####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reconstruct(object):\n",
    "    \n",
    "    def __init__(self, edge, bin_data, GMM, label, Num_of_bins, x, y, z=0):\n",
    "        self.edge = edge\n",
    "        self.bin_data = bin_data\n",
    "        self.GMM = GMM\n",
    "        self.label = label\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.Num_of_bins = Num_of_bins\n",
    "        if z != 0:\n",
    "            self.reconstructed_data = np.full((self.x, self.y, self.z, self.Num_of_bins), 0)\n",
    "        else:\n",
    "            self.reconstructed_data = np.full((self.x, self.y, self.Num_of_bins), 0)\n",
    "    \n",
    "    def reconstruct(self, time): #bin: [index, prob, Gmm label, Num of component]\n",
    "        if self.z!=0:\n",
    "            for x in range(self.x):\n",
    "                for y in range(self.y):\n",
    "                    for z in range(self.z):\n",
    "                        self.reconstructed_data[x,y,z] = self.grid_reconstruct(self.bin_data[x,y,z], time)\n",
    "        else:\n",
    "            for x in range(self.x):\n",
    "                for y in range(self.y):\n",
    "                    self.reconstructed_data[x,y] = self.grid_reconstruct(self.bin_data[x,y], time)\n",
    "\n",
    "    def grid_reconstruct(self, grid, time_step):\n",
    "        numOfbin = len(grid)\n",
    "        f = np.zeros(numOfbin)\n",
    "        p = np.zeros(numOfbin)\n",
    "        bin_count=0\n",
    "        for bin in grid:\n",
    "            if(bin[0] == -1): \n",
    "                f[bin_count] = 0\n",
    "                p[bin_count] = 0\n",
    "            else:\n",
    "                GMM_prob = 0\n",
    "                bin_index = bin[0]\n",
    "                bar_prob = bin[1]\n",
    "                Gmm_label = int(bin[2])\n",
    "                start = int(self.label[Gmm_label])\n",
    "                n_comp = int(bin[3])\n",
    "                end = int(start+n_comp)\n",
    "                # print('start: ', start, 'end: ',end)\n",
    "                weights = self.GMM[0][start:end]\n",
    "                means = self.GMM[1][start:end]\n",
    "                covars = self.GMM[2][start:end]\n",
    "                for n_components in range(n_comp):\n",
    "                    GMM_prob += weights[n_components] * (np.exp((-((time_step-means[n_components])**2))/(2*(np.sqrt(covars[n_components])**2))) / np.sqrt(2*np.pi*(np.sqrt(covars[n_components])**2)))\n",
    "                f[bin_count] = GMM_prob\n",
    "                p[bin_count] = bar_prob\n",
    "                start += int(n_comp)\n",
    "            bin_count += 1\n",
    "        postProb = f * p\n",
    "        postProbSum = np.sum(postProb)\n",
    "        postProb = postProb / postProbSum\n",
    "        return postProb\n",
    "                                       \n",
    "    \n",
    "    def _compute_cdf(self, pdf, edge, x):\n",
    "        allcdf = np.cumsum(pdf)\n",
    "        allcdf = np.hstack([0.0, allcdf])\n",
    "        cdf = np.interp(x, edge, allcdf, left=0, right=0)\n",
    "        return cdf\n",
    "           \n",
    "    \n",
    "    def compute_isovalue(self, reconst_data, iso_value):\n",
    "        hist_edge = self.edge\n",
    "        \n",
    "        if self.z!=0:\n",
    "            cdf = np.zeros((self.x, self.y, self.z))\n",
    "            for i in range(self.x):\n",
    "                for j in range(self.y):\n",
    "                    for k in range(self.z):\n",
    "                        cdf[i,j,k] = self._compute_cdf(reconst_data[i,j,k], hist_edge, iso_value)\n",
    "            cdf_1_c = 1 - cdf\n",
    "            pCrossing = np.zeros((self.x, self.y, self.z))\n",
    "            for l in range(self.x):\n",
    "                for m in range(self.y):\n",
    "                    for n in range(self.z):\n",
    "                        if(l == self.x-1):\n",
    "                            pCrossing[l, m, n] = pCrossing[l-1, m, n]\n",
    "                        elif(m == self.y-1):\n",
    "                            pCrossing[l, m, n] = pCrossing[l, m-1, n]\n",
    "                        elif(n == self.z-1):\n",
    "                            pCrossing[l, m, n] = pCrossing[l, m, n-1]   \n",
    "                        else:\n",
    "                            prob = cdf[l, m, n] * cdf[l+1, m, n] * cdf[l, m+1, n] * cdf[l, m, n+1] * cdf[l+1, m+1, n] * cdf[l+1, m, n+1] * cdf[l, m+1, n+1] * cdf[l+1, m+1, n+1]\n",
    "                            prob2 = cdf_1_c[l, m, n] * cdf_1_c[l+1, m, n] * cdf_1_c[l, m+1, n] * cdf_1_c[l, m, n+1] * cdf_1_c[l+1, m+1, n] * cdf_1_c[l+1, m, n+1] * cdf_1_c[l, m+1, n+1] * cdf_1_c[l+1, m+1, n+1]\n",
    "                            pCrossing[l, m, n] = 1 - prob - prob2\n",
    "        else:    \n",
    "            cdf = np.zeros((self.x, self.y))\n",
    "            for i in range(self.x):\n",
    "                for j in range(self.y):\n",
    "                    cdf[i,j] = self._compute_cdf(reconst_data[i,j], hist_edge, iso_value)\n",
    "            cdf_1_c = 1 - cdf\n",
    "            pCrossing = np.zeros((self.x, self.y))\n",
    "            for k in range(self.x):\n",
    "                for l in range(self.y):\n",
    "                    if(l == self.y-1):\n",
    "                        pCrossing[k, l] = pCrossing[k, l-1]\n",
    "                    elif(k == self.x-1):\n",
    "                        pCrossing[k, l] = pCrossing[k-1, l]\n",
    "                    else:\n",
    "                        prob = cdf[k, l] * cdf[k, l+1] * cdf[k+1, l] * cdf[k+1, l+1]\n",
    "                        prob2 = cdf_1_c[k, l] * cdf_1_c[k, l+1] * cdf_1_c[k+1, l] * cdf_1_c[k+1, l+1]\n",
    "                        pCrossing[k, l] = 1 - prob - prob2\n",
    "        return pCrossing\n",
    "        \n",
    "    \n",
    "    def all_reconstruct(self, time): #bin: [index, prob, Gmm label, Num of component]\n",
    "        if self.z!=0:\n",
    "            reconstructed_data = np.zeros((self.x, self.y, self.z, self.Num_of_bins, time))\n",
    "            for x in range(self.x):\n",
    "                for y in range(self.y):\n",
    "                    for z in range(self.z):\n",
    "                        reconstructed_data[x,y,z] = self._all_times_reconstruct(self.bin_data[x,y,z], time)\n",
    "        else:\n",
    "            reconstructed_data = np.zeros((self.x, self.y, self.Num_of_bins, time))\n",
    "            for x in range(self.x):\n",
    "                for y in range(self.y):\n",
    "                    reconstructed_data[x,y] = self._all_times_reconstruct(self.bin_data[x,y], time)\n",
    "        return reconstructed_data\n",
    "    \n",
    "    def new_all_reconstruct(self, time):\n",
    "        if self.z != 0 :\n",
    "            reconstruct_bin = np.full((self.x, self.y, self.z, self.Num_of_bins, 4), -1.00)\n",
    "            reconstructed_data = np.zeros((self.x, self.y, self.z, self.Num_of_bins, time))\n",
    "            for bin in self.bin_data:\n",
    "                grid_index = bin[0]\n",
    "                bin_index = int(bin[1])\n",
    "                x_location = int(grid_index//(self.y*self.z))\n",
    "                y_location = int((grid_index%(self.y*self.z))//self.z)\n",
    "                z_location = int((grid_index%(self.y*self.z))%self.z)\n",
    "                reconstruct_bin[x_location, y_location, z_location, bin_index] = bin[1:]\n",
    "            for x in range(self.x):\n",
    "                for y in range(self.y):\n",
    "                    for z in range(self.z):\n",
    "                        reconstructed_data[x,y,z] = self._all_times_reconstruct(reconstruct_bin[x,y,z], time)\n",
    "        else:\n",
    "            reconstruct_bin = np.full((self.x, self.y, self.Num_of_bins, 4), -1.00)\n",
    "            reconstructed_data = np.zeros((self.x, self.y, self.Num_of_bins, time))\n",
    "            for bin in self.bin_data:\n",
    "                grid_index = int(bin[0])\n",
    "                bin_index = int(bin[1])\n",
    "                x_location = int(grid_index//self.y)\n",
    "                y_location = int(grid_index%self.y)\n",
    "                reconstruct_bin[x_location, y_location, bin_index] = bin[1:]\n",
    "            for x in range(self.x):\n",
    "                for y in range(self.y):\n",
    "                    reconstructed_data[x,y] = self._all_times_reconstruct(reconstruct_bin[x,y], time)\n",
    "        return reconstructed_data\n",
    "            \n",
    "    \n",
    "    def _all_times_reconstruct(self, grid, time):\n",
    "        all_time_stpes = np.arange(time)\n",
    "        numOfbin = len(grid)\n",
    "        postProb = np.zeros((numOfbin,len(all_time_stpes)))\n",
    "        bin_count=0\n",
    "        SumpostProb = np.zeros(len(all_time_stpes))\n",
    "        for bin in grid:\n",
    "            if(bin[0] == -1):\n",
    "                bin_count +=1\n",
    "            else:\n",
    "                GMM_prob = np.zeros(len(all_time_stpes))\n",
    "                bin_index = bin[0]\n",
    "                bar_prob = bin[1]\n",
    "                Gmm_label = int(bin[2])\n",
    "                start = int(self.label[Gmm_label])\n",
    "                n_comp = int(bin[3])\n",
    "                end = int(start+n_comp)\n",
    "                weights = self.GMM[0][start:end]\n",
    "                means = self.GMM[1][start:end]\n",
    "                covars = self.GMM[2][start:end]\n",
    "                for n_components in range(n_comp):\n",
    "                        GMM_prob += weights[n_components] * (np.exp((-((all_time_stpes-means[n_components])**2))/(2*(np.sqrt(covars[n_components])**2))) / \n",
    "                                                             np.sqrt(2*np.pi*(np.sqrt(covars[n_components])**2)))\n",
    "                tempPostProb = GMM_prob * bar_prob \n",
    "                SumpostProb += tempPostProb \n",
    "                postProb[bin_count] = tempPostProb\n",
    "                start += int(n_comp)\n",
    "                bin_count += 1\n",
    "        postProb = postProb/SumpostProb\n",
    "        return postProb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolated_hist(data, numOfTimeStep, numOfensemble, interval):\n",
    "    data_size = data.shape\n",
    "    min_of_data = data.min()    \n",
    "    max_of_data = data.max()\n",
    "    NumOfBinsL = 0\n",
    "    NumOfBinsR = 0\n",
    "    x = data_size[0]\n",
    "    y = data_size[1]\n",
    "    z = data_size[2]\n",
    "    if(len(data_size)>3):\n",
    "        inter_hist_prob = np.zeros((x,y,z,numOfTimeStep,128))\n",
    "    else:\n",
    "        inter_hist_prob = np.zeros((x,y,numOfTimeStep,128))\n",
    "    # print('interp_hist_prob shape', inter_hist_prob.shape)\n",
    "    selected_time = np.arange(0, numOfTimeStep, interval)\n",
    "    selected_time = selected_time-1\n",
    "    selected_time[0] = 0\n",
    "    endtime = selected_time[-1]+interval\n",
    "    if endtime >= numOfTimeStep:\n",
    "        endtime = numOfTimeStep-1\n",
    "    selected_time = np.append(selected_time,endtime)\n",
    "    print(selected_time)\n",
    "    for select_index in range(len(selected_time)-1):\n",
    "        left_time = selected_time[select_index]\n",
    "        right_time = selected_time[select_index+1]\n",
    "        # print('left: ', left_time,' right: ',right_time)\n",
    "        if(len(data_size)>3):\n",
    "            for i in range(x):\n",
    "                for j in range(y):\n",
    "                    for k in range(z):\n",
    "                        reconstruct_time = np.arange(left_time,right_time)\n",
    "                        rawdataL = data[i, j, k, (left_time*numOfensemble):(left_time*numOfensemble)+numOfensemble]\n",
    "                        rawdataR = data[i, j, k, (right_time*numOfensemble):(right_time*numOfensemble)+numOfensemble]\n",
    "                        histL = np.histogram(rawdataL, bins=128, range=(min_of_data, max_of_data))[0]\n",
    "                        histR = np.histogram(rawdataR, bins=128, range=(min_of_data, max_of_data))[0]\n",
    "                        NumOfBinsL += np.count_nonzero(histL)\n",
    "                        # print('L: ',NumOfBinsL)\n",
    "                        if right_time == selected_time[-1]:\n",
    "                            NumOfBinsR  += np.count_nonzero(histR)\n",
    "                            # print('R: ',NumOfBinsR)\n",
    "                        for time_index in reconstruct_time:\n",
    "                            interhist = histL + (((histR-histL)/interval) * (time_index-left_time))\n",
    "                            inter_hist_prob[i,j,k,time_index] = interhist/np.sum(interhist)\n",
    "            # print('left time:',left_time,' num_of_bins: ', (NumOfBinsL+NumOfBinsR))                    \n",
    "        else:\n",
    "            for i in range(x):\n",
    "                for j in range(y):\n",
    "                    reconstruct_time = np.arange(left_time,right_time)\n",
    "                    rawdataL = data[i, j, (left_time*numOfensemble):(left_time*numOfensemble)+numOfensemble]\n",
    "                    rawdataR = data[i, j, (right_time*numOfensemble):(right_time*numOfensemble)+numOfensemble]\n",
    "                    histL = np.histogram(rawdataL, bins=128, range=(min_of_data, max_of_data))[0]\n",
    "                    histR = np.histogram(rawdataR, bins=128, range=(min_of_data, max_of_data))[0]\n",
    "                    NumOfBinsL += np.count_nonzero(histL)\n",
    "                    if right_time == selected_time[-1]:\n",
    "                        NumOfBinsR  += np.count_nonzero(histR)\n",
    "                    for time_index in reconstruct_time:\n",
    "                        interhist = histL + (((histR-histL)/interval) * (time_index-left_time))\n",
    "                        inter_hist_prob[i,j,time_index] = interhist/np.sum(interhist)\n",
    "    storage = (((NumOfBinsL+NumOfBinsR)*4*32)/8)/1000000  \n",
    "    print('storage: ', storage,'(MB)')\n",
    "    return inter_hist_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(reconstruction, raw):\n",
    "    data_size = reconstruction.shape\n",
    "    if (len(reconstruction.shape) >3):\n",
    "        data_x = data_size[0]\n",
    "        data_y = data_size[1]\n",
    "        data_z = data_size[2] \n",
    "        rmse = np.sum((np.sum((reconstruction - raw)**2, axis=3)/128)**(1/2))\n",
    "        rmse = rmse/(data_x*data_y*data_z)\n",
    "    else:\n",
    "        data_x = data_size[0]\n",
    "        data_y = data_size[1]\n",
    "        rmse = np.sum((np.sum((reconstruction - raw)**2, axis=2)/128)**(1/2))\n",
    "        rmse = rmse/(data_x*data_y)\n",
    "    return rmse               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3Disovalue(hist_dist, isovalue):\n",
    "    pcrossing = np.zeros((32,32,32))\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            for k in range(32):\n",
    "                if(j == 31):\n",
    "                    pcrossing[i, j, k] = pcrossing[i, j-1, k]\n",
    "                elif(i == 31):\n",
    "                    pcrossing[i, j, k] = pcrossing[i-1, j, k]\n",
    "                elif(k == 31):\n",
    "                    pcrossing[i, j, k] = pcrossing[i, j, k-1]\n",
    "                else:\n",
    "                    prob = hist_dist[i, j, k].cdf(isovalue)*hist_dist[i,j+1,k].cdf(isovalue)*hist_dist[i+1,j,k].cdf(isovalue)*hist_dist[i,j,k+1].cdf(isovalue)*hist_dist[i+1,j+1,k].cdf(isovalue)*hist_dist[i+1,j,k+1].cdf(isovalue)*hist_dist[i,j+1,k+1].cdf(isovalue)*hist_dist[i+1,j+1,k+1].cdf(isovalue)\n",
    "                    prob2 = (1-hist_dist[i, j,k].cdf(isovalue))*(1-hist_dist[i, j+1,k].cdf(isovalue))*(1-hist_dist[i+1, j,k].cdf(isovalue))*(1-hist_dist[i, j, k+1].cdf(isovalue))*(1-hist_dist[i+1, j+1, k].cdf(isovalue))*(1-hist_dist[i+1, j, k+1].cdf(isovalue))*(1-hist_dist[i, j+1, k+1].cdf(isovalue))*(1-hist_dist[i+1, j+1, k+1].cdf(isovalue))\n",
    "                    pcrossing[i, j, k] = 1 - prob - prob2\n",
    "    return pcrossing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_isovalue(hist_dist, isovalue):\n",
    "    pcrossing = np.zeros((160,320))\n",
    "    for i in range(160):\n",
    "        for j in range(320):\n",
    "            if(j == 159):\n",
    "                pcrossing[i, j] = pcrossing[i, j-1]\n",
    "            elif(i == 319):\n",
    "                pcrossing[i, j] = pcrossing[i-1, j]\n",
    "            else:\n",
    "                prob = hist_dist[i, j].cdf(isovalue)*hist_dist[i,j+1].cdf(isovalue)*hist_dist[i+1,j].cdf(isovalue)*hist_dist[i+1,j+1].cdf(isovalue)\n",
    "                prob2 = (1-hist_dist[i, j].cdf(isovalue))*(1-hist_dist[i, j+1].cdf(isovalue))*(1-hist_dist[i+1, j].cdf(isovalue))*(1-hist_dist[i+1, j+1].cdf(isovalue))\n",
    "                pcrossing[i, j] = 1 - prob - prob2\n",
    "    return pcrossing    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_interp_isovalue(interp_data ,edge, isovalue):\n",
    "    if len(interp_data.shape) > 3:\n",
    "        x = interp_data.shape[0]\n",
    "        y = interp_data.shape[1]\n",
    "        z = interp_data.shape[2]\n",
    "        cdf = np.zeros((x,y,z))\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                for k in range(z):\n",
    "                    allcdf = np.cumsum(interp_data[i,j,k])\n",
    "                    allcdf = np.hstack([0.0, allcdf])\n",
    "                    cdf[i,j,k] = np.interp(isovalue, edge, allcdf, left=0, right=0)\n",
    "        cdf_1_c = 1 - cdf\n",
    "        pCrossing = np.zeros((x,y,z))\n",
    "        for l in range(x):\n",
    "            for m in range(y):\n",
    "                for n in range(z):\n",
    "                    if(l == x-1):\n",
    "                        pCrossing[l,m,n] = pCrossing[l-1,m,n]\n",
    "                    elif(m == y-1):\n",
    "                        pCrossing[l,m,n] = pCrossing[l,m-1,n]\n",
    "                    elif(n == z-1):\n",
    "                        pCrossing[l,m,n] = pCrossing[l,m,n-1]\n",
    "                    else:\n",
    "                        prob = cdf[l, m, n] * cdf[l+1, m, n] * cdf[l, m+1, n] * cdf[l, m, n+1] * cdf[l+1, m+1, n] * cdf[l+1, m, n+1] * cdf[l, m+1, n+1] * cdf[l+1, m+1, n+1]\n",
    "                        prob2 = cdf_1_c[l, m, n] * cdf_1_c[l+1, m, n] * cdf_1_c[l, m+1, n] * cdf_1_c[l, m, n+1] * cdf_1_c[l+1, m+1, n] * cdf_1_c[l+1, m, n+1] * cdf_1_c[l, m+1, n+1] * cdf_1_c[l+1, m+1, n+1]\n",
    "                        pCrossing[l, m, n] = 1 - prob - prob2\n",
    "    else:\n",
    "        x = interp_data.shape[0]\n",
    "        y = interp_data.shape[1]\n",
    "        cdf = np.zeros((x,y))\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                allcdf = np.cumsum(interp_data[i,j])\n",
    "                allcdf = np.hstack([0.0, allcdf])\n",
    "                cdf[i,j] = np.interp(isovalue, edge, allcdf, left=0, right=0)\n",
    "        cdf_1_c = 1 - cdf\n",
    "        pCrossing = np.zeros((x,y))\n",
    "        for k in range(x):\n",
    "            for l in range(y):\n",
    "                if(l == y-1):\n",
    "                    pCrossing[k,l] = pCrossing[k,l-1]\n",
    "                elif(k == x-1):\n",
    "                    pCrossing[k,l] = pCrossing[k-1,l]\n",
    "                else:\n",
    "                    prob = cdf[k, l] * cdf[k, l+1] * cdf[k+1, l] * cdf[k+1, l+1]\n",
    "                    prob2 = cdf_1_c[k, l] * cdf_1_c[k, l+1] * cdf_1_c[k+1, l] * cdf_1_c[k+1, l+1]\n",
    "                    pCrossing[k, l] = 1 - prob - prob2\n",
    "    return pCrossing            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_raw_bin(bin_data, x, y, z, TotalTimesteps, NumOfBins, NumOfEnsemble):\n",
    "    if(z != 0):\n",
    "       Reconted_data = np.zeros((TotalTimesteps, x, y, z, NumOfBins))\n",
    "       for bin in bin_data:\n",
    "           timestep = int(bin[0])\n",
    "           x_location = int(bin[1]//(y*z))\n",
    "           y_location = int((bin[1]%(y*z))//z)\n",
    "           z_location = int((bin[1]%(y*z))%z)\n",
    "           bin_index = int(bin[2])\n",
    "           bin_prob = bin[3]/NumOfEnsemble\n",
    "           Reconted_data[timestep, x_location, y_location, z_location, bin_index] = bin_prob\n",
    "    else:\n",
    "        Reconted_data = np.zeros((int(bin_data[:,0].max()+1), x, y, NumOfBins))\n",
    "        for bin in bin_data:\n",
    "            timestep = int(bin[0])\n",
    "            x_location = int(bin[1]//y)\n",
    "            y_location = int(bin[1]%y)\n",
    "            if(y_location>=128):\n",
    "                bin_index = 127\n",
    "            bin_index = int(bin[2])\n",
    "            if(bin_index>=128):\n",
    "                bin_index = 127\n",
    "            bin_prob = bin[3]/NumOfEnsemble\n",
    "            Reconted_data[timestep, x_location, y_location, bin_index] = bin_prob\n",
    "    return Reconted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_create_reconstruct(floder_path, num_of_bins, start_time, end_time, x, y, z=0):\n",
    "    # bin_data_name = 'bin_data_x160_y320_NumOfbBins128_time_range_{start_time}_{end_time}.bin'.format(start_time=start_time, end_time=end_time)\n",
    "    # bin_data_name = 'bin_data_x32_y32_z32_NumOfBins128_RangeOfTimestime_range_{start_time}_{end_time}.bin'.format(start_time=start_time, end_time=end_time)\n",
    "    bin_data_name = 'bin_data_x25_y20_z120_NumOfBins128_RangeOfTimestime_range_{start_time}_{end_time}.bin'.format(start_time=start_time, end_time=end_time)\n",
    "    edge_name = 'edge_time_range_{start_time}_{end_time}.bin'.format(start_time=start_time, end_time=end_time)\n",
    "    model_name = 'Gmm_time_range_{start_time}_{end_time}.bin'.format(start_time=start_time, end_time=end_time)\n",
    "    label_name = 'label_time_range_{start_time}_{end_time}.bin'.format(start_time=start_time, end_time=end_time)\n",
    "    bin_data_path = os.path.join(floder_path, bin_data_name)\n",
    "    edge_path = os.path.join(floder_path, edge_name)\n",
    "    model_path = os.path.join(floder_path, model_name)\n",
    "    \n",
    "    label_path = os.path.join(floder_path, label_name)\n",
    "    bin_data = np.fromfile(bin_data_path, dtype=np.float32)\n",
    "    bin_data = bin_data.reshape((len(bin_data)//5, 5))\n",
    "    edge = np.fromfile(edge_path, dtype=np.float32)\n",
    "    model = np.fromfile(model_path, dtype=np.float32)\n",
    "    model = model.reshape((3, len(model)//3))\n",
    "    label = np.fromfile(label_path, dtype=np.float32)\n",
    "    # print('bin data name: ', bin_data_name)\n",
    "    # print('edge name: ', edge_name)\n",
    "    # print('model name: ', model_name)\n",
    "    # print('label name: ', label_name)\n",
    "    \n",
    "    return reconstruct(edge, bin_data, model, label, num_of_bins, x, y, z)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, x, y, z=0):\n",
    "    error = np.zeros(timesteps)\n",
    "    for s_time in range(0, timesteps, cons_time):\n",
    "        end_time = s_time+cons_time\n",
    "        # print('start: ', s_time, ' end: ', end_time)\n",
    "        reconstruction = quick_create_reconstruct(floder_path, num_of_bins, s_time, end_time, x, y, z)\n",
    "        reconstruction_data = reconstruction.new_all_reconstruct(cons_time)\n",
    "        if (z == 0):\n",
    "            for timestep in range(cons_time):\n",
    "                error[s_time+timestep] = compute_error(reconstruction_data[:,:,:,timestep], raw_hist_data[s_time+timestep])\n",
    "        else:\n",
    "            for timestep in range(cons_time):\n",
    "                error[s_time+timestep] = compute_error(reconstruction_data[:,:,:,:,timestep], raw_hist_data[s_time+timestep])\n",
    "    error.astype('float32').tofile(floder_path+'\\\\timesteps150_error.bin')\n",
    "    RMSE_txt = floder_path+'\\\\RMSE.txt'\n",
    "    text_file = open(RMSE_txt, 'w')\n",
    "    print('RMSE: ', np.sum(error)/timesteps, file = text_file)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_raw_reconsted = np.fromfile('./Data_set/AirTemp_raw_reconted_Timesteps150_x160_y320_NumOfBins128.bin', dtype=np.float32).reshape((150,160,320,128))\n",
    "air_data = np.load('./Data_set/Air_temp_160_320_ensemble60_timestep150.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\User\\\\Desktop\\\\master thesis\\\\Experiment\\\\Tgmm_slic\\\\Airta\\\\160_320\\\\75'\n",
    "floder_list = os.listdir(path)\n",
    "raw_hist_data = air_raw_reconsted\n",
    "timesteps = 150\n",
    "cons_time = 75\n",
    "num_of_bins = 128\n",
    "for i in range (0,len(floder_list),13):\n",
    "    print(floder_list[i])\n",
    "    floder_path = os.path.join(path, floder_list[i])\n",
    "    compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, 160, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  29  59  89 119 149]\n",
      "storage:  14.149488 (MB)\n",
      "error:  0.05571792989582556\n"
     ]
    }
   ],
   "source": [
    "climate_interp = interpolated_hist(air_data, 150, 60, 30)\n",
    "climate_interp_error = np.zeros(150)\n",
    "for i in range(150):\n",
    "    climate_interp_error[i] = compute_error(climate_interp[:,:,i], air_raw_reconsted[i])\n",
    "climate_interp_error.astype('float32').tofile('climate_interp_sampletime30_error.bin')\n",
    "print('error: ', sum(climate_interp_error)/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\User\\\\Desktop\\\\master thesis\\\\Experiment\\\\Tgmm_slic\\\\Nyx_density\\\\New_32CUBE\\\\200'\n",
    "floder_list = os.listdir(path)\n",
    "floder_path = os.path.join(path, floder_list[-1])\n",
    "error_path = os.path.join(floder_path, os.listdir(floder_path)[-2])\n",
    "error = np.fromfile(error_path, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyx_reconsted = quick_create_reconstruct(floder_path, 128, 0, 200,32,32,32)\n",
    "nyx_reconst_data = nyx_reconsted.new_all_reconstruct(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyx_raw_reconsted = np.fromfile('./Data_set/nyx_32cube_raw_reonted_200_32_32_32_128.bin', dtype=np.float32).reshape((200,32,32,32,128))\n",
    "nyx_data = np.load('./Data_set/nyx_density_32cube_ensemble64_timestep200.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   9  19  29  39  49  59  69  79  89  99 109 119 129 139 149 159 169\n",
      " 179 189 199]\n",
      "storage:  17.638576 (MB)\n",
      "error:  0.04127082979862939\n"
     ]
    }
   ],
   "source": [
    "interp = interpolated_hist(nyx_data, 200, 64, 10)\n",
    "nyx_interp_error = np.zeros(200)\n",
    "for i in range(200):\n",
    "    nyx_interp_error[i] = compute_error(interp[:,:,:,i], nyx_raw_reconsted[i])\n",
    "nyx_interp_error.astype('float32').tofile('Nyx_interp_10_error.bin')\n",
    "print('error: ', sum(nyx_interp_error)/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nyx_32Cube_NumOfEns64_Timesteps200_ConsTimes50_NumOfComps1_NonSLIC\n",
      "Nyx_32Cube_NumOfEns64_Timesteps200_ConsTimes50_NumOfComps3_NonSLIC\n",
      "Nyx_32Cube_NumOfEns64_Timesteps200_ConsTimes50_NumOfComps5_NonSLIC\n",
      "Nyx_32Cube_NumOfEns64_Timesteps200_ConsTimes50_NumOfComps7_NonSLIC\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\User\\\\Desktop\\\\master thesis\\\\Experiment\\\\Tgmm_slic\\\\Nyx_density\\\\New_32CUBE\\\\50'\n",
    "floder_list = os.listdir(path)\n",
    "raw_hist_data = nyx_raw_reconsted\n",
    "timesteps = 200\n",
    "cons_time = 50\n",
    "num_of_bins = 128\n",
    "for i in range (0,len(floder_list),5):\n",
    "    print(floder_list[i])\n",
    "    floder_path = os.path.join(path, floder_list[i])\n",
    "    compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, 32, 32, 32)\n",
    "\n",
    "# for floder in floder_list:\n",
    "#     print(floder)\n",
    "#     floder_path = os.path.join(path, floder)\n",
    "#     compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, 32, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nyx_32Cube_NumOfEns64_Timesteps200_ConsTimes100_NumOfComps1_SLIC_64_100_12\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\User\\\\Desktop\\\\master thesis\\\\Experiment\\\\Tgmm_slic\\\\Nyx_density\\\\New_32CUBE\\\\100'\n",
    "floder_list = os.listdir(path)\n",
    "raw_hist_data = nyx_raw_reconsted\n",
    "timesteps = 200\n",
    "cons_time = 100\n",
    "num_of_bins = 128\n",
    "for i in range(1,len(floder_list),20):\n",
    "    floder = floder_list[i]\n",
    "    print(floder_list[i])\n",
    "    floder_path = os.path.join(path, floder)\n",
    "    compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, 32, 32, 32)\n",
    "\n",
    "# for floder in floder_list:\n",
    "#     print(floder)\n",
    "#     floder_path = os.path.join(path, floder)\n",
    "#     compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, 32, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "redsea_data = np.load('./Data_set/RedSea_salt_25_20_120_ensemble50_timestep60.npy')\n",
    "redsea_raw_reconsted = np.fromfile('./Data_set/RedSea_raw_reconted_60_25_20_120_128.bin', dtype=np.float32).reshape((60,25,20,120,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.009344510949768766\n"
     ]
    }
   ],
   "source": [
    "redsea_interp = interpolated_hist(redsea_data, 60, 50, 8)\n",
    "redsea_interp_error = np.zeros(60)\n",
    "for i in range(60):\n",
    "    redsea_interp_error[i] = compute_error(redsea_interp[:,:,:,i], redsea_raw_reconsted[i])\n",
    "redsea_interp_error.astype('float32').tofile('redsea_interp_sampletime8_error.bin')\n",
    "print('error: ', sum(redsea_interp_error)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps5_SLIC_1024_50_3\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps5_SLIC_1024_50_5\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps5_SLIC_1024_50_7\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps5_SLIC_1024_50_9\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps7_SLIC_1024_50_3\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps7_SLIC_1024_50_5\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps7_SLIC_1024_50_7\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes30_NumOfComps7_SLIC_1024_50_9\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\User\\\\Desktop\\\\master thesis\\\\Experiment\\\\Tgmm_slic\\\\RedSea\\\\new\\\\30'\n",
    "floder_list = os.listdir(path)\n",
    "raw_hist_data = redsea_raw_reconsted\n",
    "timesteps = 60\n",
    "cons_time = 30\n",
    "num_of_bins = 128\n",
    "for i in range(8,len(floder_list)):\n",
    "    floder = floder_list[i]\n",
    "    print(floder_list[i])\n",
    "    floder_path = os.path.join(path, floder)\n",
    "    compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, 25, 20, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps1_SLIC_1024_50_3\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps1_SLIC_1024_50_5\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps1_SLIC_1024_50_7\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps1_SLIC_1024_50_9\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps3_SLIC_1024_50_3\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps3_SLIC_1024_50_5\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps3_SLIC_1024_50_7\n",
      "Redsea_NumOfEns50_Timesteps60_ConsTimes20_NumOfComps3_SLIC_1024_50_9\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\User\\\\Desktop\\\\master thesis\\\\Experiment\\\\Tgmm_slic\\\\RedSea\\\\new\\\\20'\n",
    "floder_list = os.listdir(path)\n",
    "raw_hist_data = redsea_raw_reconsted\n",
    "timesteps = 60\n",
    "cons_time = 20\n",
    "num_of_bins = 128\n",
    "for i in range(0,8):\n",
    "    floder = floder_list[i]\n",
    "    print(floder_list[i])\n",
    "    floder_path = os.path.join(path, floder)\n",
    "    compute_file_error(floder_path, raw_hist_data, timesteps, cons_time, num_of_bins, 25, 20, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Air_temp_180_320_ensemble60_timestep150.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\TGMM\\Reconstruct.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TGMM/Reconstruct.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m air_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mAir_temp_180_320_ensemble60_timestep150.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TGMM/Reconstruct.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m inter_ta_error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m150\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TGMM/Reconstruct.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m150\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TGMM_3\\lib\\site-packages\\numpy\\lib\\npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 417\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    418\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Air_temp_180_320_ensemble60_timestep150.npy'"
     ]
    }
   ],
   "source": [
    "air_data = np.load('Air_temp_180_320_ensemble60_timestep150.npy')\n",
    "inter_ta_error = np.zeros(150)\n",
    "for i in range(150):\n",
    "    inter_ta_error[i] = compute_error(interpolated_hist(air_data, 150, 60, 10, i),air_raw_reconsted)\n",
    "inter_ta_error.astype('float32').tofile('air_ta_interp_10_error.bin')\n",
    "print('air ta interp 10 error: ', np.sum(inter_ta_error)/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "fig = plt.figure(figsize = (30,5))\n",
    "vmin = np.min(air_raw_iso)\n",
    "vmax = np.max(air_raw_iso)\n",
    "norm = matplotlib.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "plt.subplot(1,4,1)\n",
    "rawplot = plt.imshow(air_raw_iso,cmap='coolwarm' , norm = norm, origin='lower')\n",
    "plt.title('Raw')\n",
    "# p1 = plt.colorbar(rawplot)\n",
    "\n",
    "# plt.subplot(1,4,2)\n",
    "# slic4_plot = plt.imshow(sz_air_iso, cmap='coolwarm', norm = norm, origin='lower')\n",
    "# plt.title('sz')\n",
    "# # p2 = plt.colorbar(slic4_plot)\n",
    "\n",
    "# plt.subplot(1,4,3)\n",
    "# slic8_plot = plt.imshow(inter_iso, cmap='coolwarm', norm = norm,origin='lower')\n",
    "# plt.title('inter')\n",
    "# p3 = plt.colorbar(slic8_plot)\n",
    "\n",
    "# plt.subplot(1,4,4)\n",
    "# slic64_plot = plt.imshow(airtemp_7_50_time_1_iso, cmap='coolwarm', norm = norm, origin='lower')\n",
    "# plt.title('SLIC comp 12')\n",
    "# # p3 = plt.colorbar(slic64_plot)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "797dde4d81f7598b75161dc3af3c72e0851d7c9155a7e461083543e66c3c78b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('TGMM_3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
